import json
import pandas as pd
import os
from datetime import datetime
import re
from typing import List, Dict, Any

class DataPreprocessor:
    def __init__(self, data_dir="shopify_training_data"):
        self.data_dir = data_dir
        self.processed_data = []
        
    def load_raw_data(self):
        """Ham verileri yÃ¼kle"""
        all_data = []
        
        # JSON dosyalarÄ±nÄ± yÃ¼kle
        for filename in os.listdir(self.data_dir):
            if filename.endswith('.json'):
                filepath = os.path.join(self.data_dir, filename)
                try:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        if isinstance(data, list):
                            all_data.extend(data)
                        else:
                            all_data.append(data)
                    print(f"âœ… YÃ¼klendi: {filepath} ({len(data) if isinstance(data, list) else 1} kayÄ±t)")
                except Exception as e:
                    print(f"âŒ YÃ¼kleme hatasÄ± {filepath}: {e}")
        
        print(f"ğŸ“Š Toplam ham veri: {len(all_data)} kayÄ±t")
        return all_data
    
    def clean_text(self, text):
        """Metni temizle ve normalize et"""
        if not text or not isinstance(text, str):
            return ""
        
        # HTML etiketlerini kaldÄ±r
        text = re.sub(r'<[^>]+>', ' ', text)
        
        # Fazla boÅŸluklarÄ± temizle
        text = re.sub(r'\s+', ' ', text)
        
        # Ã–zel karakterleri temizle
        text = re.sub(r'[^\w\s\.,!?;:()-]', ' ', text)
        
        # BaÅŸtan ve sondan boÅŸluklarÄ± kaldÄ±r
        text = text.strip()
        
        return text
    
    def extract_features(self, product_data):
        """ÃœrÃ¼n verisinden Ã¶zellikler Ã§Ä±kar"""
        features = {
            'title': self.clean_text(product_data.get('title', '')),
            'description': self.clean_text(product_data.get('description', '')),
            'category': self.clean_text(product_data.get('category', '')),
            'price': product_data.get('price', ''),
            'features_list': product_data.get('features', [])
        }
        
        # Fiyat iÅŸleme
        if features['price']:
            # Fiyattan sadece sayÄ±larÄ± Ã§Ä±kar
            price_match = re.search(r'[\d,]+\.?\d*', str(features['price']))
            if price_match:
                features['price_numeric'] = float(price_match.group().replace(',', ''))
            else:
                features['price_numeric'] = 0
        else:
            features['price_numeric'] = 0
        
        # AÃ§Ä±klama uzunluÄŸu
        features['description_length'] = len(features['description'])
        
        # BaÅŸlÄ±k uzunluÄŸu
        features['title_length'] = len(features['title'])
        
        # Anahtar kelime sayÄ±sÄ±
        features['title_word_count'] = len(features['title'].split())
        features['description_word_count'] = len(features['description'].split())
        
        return features
    
    def create_training_prompts(self, product_data):
        """EÄŸitim iÃ§in prompt-response Ã§iftleri oluÅŸtur"""
        features = self.extract_features(product_data)
        
        training_examples = []
        
        # 1. BaÅŸlÄ±k oluÅŸturma gÃ¶revi
        if features['title'] and features['category']:
            prompt = f"Create a compelling Shopify product title for a {features['category']} product."
            response = features['title']
            training_examples.append({
                'instruction': prompt,
                'input': '',
                'output': response,
                'task_type': 'title_generation'
            })
        
        # 2. AÃ§Ä±klama oluÅŸturma gÃ¶revi
        if features['description'] and features['title']:
            prompt = f"Write a detailed Shopify product description for: {features['title']}"
            response = features['description']
            training_examples.append({
                'instruction': prompt,
                'input': '',
                'output': response,
                'task_type': 'description_generation'
            })
        
        # 3. Anahtar kelimeye dayalÄ± aÃ§Ä±klama
        if features['description'] and features['category']:
            prompt = f"Generate a Shopify product description for a {features['category']} product."
            response = features['description']
            training_examples.append({
                'instruction': prompt,
                'input': '',
                'output': response,
                'task_type': 'category_description'
            })
        
        # 4. Ã–zellik listesine dayalÄ± aÃ§Ä±klama
        if features['description'] and features['features_list']:
            features_text = ', '.join(features['features_list'][:5])  # Ä°lk 5 Ã¶zellik
            prompt = f"Create a product description based on these features: {features_text}"
            response = features['description']
            training_examples.append({
                'instruction': prompt,
                'input': '',
                'output': response,
                'task_type': 'feature_description'
            })
        
        return training_examples
    
    def process_data(self):
        """Verileri iÅŸle ve eÄŸitim formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼r"""
        print("ğŸ”„ Veri iÅŸleme baÅŸlÄ±yor...")
        
        raw_data = self.load_raw_data()
        all_training_examples = []
        
        for i, product in enumerate(raw_data):
            try:
                training_examples = self.create_training_prompts(product)
                all_training_examples.extend(training_examples)
                
                if (i + 1) % 100 == 0:
                    print(f"ğŸ“‹ Ä°ÅŸlenen Ã¼rÃ¼n sayÄ±sÄ±: {i + 1}")
                    
            except Exception as e:
                print(f"âŒ ÃœrÃ¼n iÅŸleme hatasÄ± {i}: {e}")
        
        print(f"âœ… Toplam eÄŸitim Ã¶rneÄŸi: {len(all_training_examples)}")
        return all_training_examples
    
    def save_training_data(self, training_data, format_type="alpaca"):
        """EÄŸitim verisini kaydet"""
        output_dir = "model_training_data"
        os.makedirs(output_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M')
        
        if format_type == "alpaca":
            # Alpaca formatÄ±nda kaydet
            filename = f"shopify_alpaca_training_{timestamp}.json"
            filepath = os.path.join(output_dir, filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(training_data, f, ensure_ascii=False, indent=2)
        
        elif format_type == "jsonl":
            # JSONL formatÄ±nda kaydet (her satÄ±rda bir JSON)
            filename = f"shopify_training_{timestamp}.jsonl"
            filepath = os.path.join(output_dir, filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                for example in training_data:
                    f.write(json.dumps(example, ensure_ascii=False) + '\n')
        
        elif format_type == "csv":
            # CSV formatÄ±nda kaydet
            filename = f"shopify_training_{timestamp}.csv"
            filepath = os.path.join(output_dir, filename)
            
            df = pd.DataFrame(training_data)
            df.to_csv(filepath, index=False, encoding='utf-8')
        
        print(f"ğŸ’¾ EÄŸitim verisi kaydedildi: {filepath}")
        return filepath
    
    def create_validation_split(self, training_data, validation_ratio=0.1):
        """EÄŸitim ve doÄŸrulama setlerini ayÄ±r"""
        import random
        
        # Veriyi karÄ±ÅŸtÄ±r
        random.shuffle(training_data)
        
        # BÃ¶lme noktasÄ±nÄ± hesapla
        split_index = int(len(training_data) * (1 - validation_ratio))
        
        train_data = training_data[:split_index]
        val_data = training_data[split_index:]
        
        print(f"ğŸ“Š EÄŸitim seti: {len(train_data)} Ã¶rnek")
        print(f"ğŸ“Š DoÄŸrulama seti: {len(val_data)} Ã¶rnek")
        
        return train_data, val_data
    
    def generate_statistics(self, training_data):
        """Veri istatistikleri oluÅŸtur"""
        stats = {
            'total_examples': len(training_data),
            'task_types': {},
            'avg_input_length': 0,
            'avg_output_length': 0,
            'output_length_distribution': {}
        }
        
        total_input_length = 0
        total_output_length = 0
        output_lengths = []
        
        for example in training_data:
            # GÃ¶rev tÃ¼rÃ¼ istatistikleri
            task_type = example.get('task_type', 'unknown')
            stats['task_types'][task_type] = stats['task_types'].get(task_type, 0) + 1
            
            # Uzunluk istatistikleri
            input_length = len(example.get('input', '') + example.get('instruction', ''))
            output_length = len(example.get('output', ''))
            
            total_input_length += input_length
            total_output_length += output_length
            output_lengths.append(output_length)
        
        stats['avg_input_length'] = total_input_length / len(training_data) if training_data else 0
        stats['avg_output_length'] = total_output_length / len(training_data) if training_data else 0
        
        # Ã‡Ä±ktÄ± uzunluk daÄŸÄ±lÄ±mÄ±
        if output_lengths:
            stats['min_output_length'] = min(output_lengths)
            stats['max_output_length'] = max(output_lengths)
            stats['median_output_length'] = sorted(output_lengths)[len(output_lengths)//2]
        
        return stats

def main():
    """Ana fonksiyon"""
    print("ğŸš€ Shopify veri Ã¶n iÅŸleme baÅŸlÄ±yor...")
    
    preprocessor = DataPreprocessor()
    
    try:
        # Veriyi iÅŸle
        training_data = preprocessor.process_data()
        
        if not training_data:
            print("âŒ Ä°ÅŸlenecek veri bulunamadÄ±!")
            return
        
        # EÄŸitim ve doÄŸrulama setlerini ayÄ±r
        train_data, val_data = preprocessor.create_validation_split(training_data)
        
        # FarklÄ± formatlarda kaydet
        print("ğŸ’¾ EÄŸitim verisi kaydediliyor...")
        preprocessor.save_training_data(train_data, "alpaca")
        preprocessor.save_training_data(train_data, "jsonl")
        
        # DoÄŸrulama setini kaydet
        preprocessor.save_training_data(val_data, "alpaca")
        
        # Ä°statistikleri oluÅŸtur ve kaydet
        stats = preprocessor.generate_statistics(training_data)
        
        stats_file = f"model_training_data/data_statistics_{datetime.now().strftime('%Y%m%d_%H%M')}.json"
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(stats, f, ensure_ascii=False, indent=2)
        
        print("ğŸ“Š Veri Ä°statistikleri:")
        print(f"  - Toplam Ã¶rnek: {stats['total_examples']}")
        print(f"  - Ortalama giriÅŸ uzunluÄŸu: {stats['avg_input_length']:.1f}")
        print(f"  - Ortalama Ã§Ä±kÄ±ÅŸ uzunluÄŸu: {stats['avg_output_length']:.1f}")
        print(f"  - GÃ¶rev tÃ¼rleri: {stats['task_types']}")
        
        print("âœ… Veri Ã¶n iÅŸleme tamamlandÄ±!")
        
    except Exception as e:
        print(f"âŒ Hata oluÅŸtu: {e}")

if __name__ == "__main__":
    main()
